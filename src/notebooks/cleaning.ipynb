{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-04T07:19:33.244217Z","iopub.status.busy":"2023-03-04T07:19:33.243735Z","iopub.status.idle":"2023-03-04T07:19:33.254234Z","shell.execute_reply":"2023-03-04T07:19:33.252869Z","shell.execute_reply.started":"2023-03-04T07:19:33.244166Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","from nltk.corpus import stopwords\n","\n","import nltk\n","print(\"jimmy\")\n","nltk.download(\"stopwords\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T07:19:34.479951Z","iopub.status.busy":"2023-03-04T07:19:34.479494Z","iopub.status.idle":"2023-03-04T07:19:34.493988Z","shell.execute_reply":"2023-03-04T07:19:34.492607Z","shell.execute_reply.started":"2023-03-04T07:19:34.479910Z"},"trusted":true},"outputs":[],"source":["def filterByNumWords(df: pd.DataFrame, numWords: int) -> pd.DataFrame:\n","    \"\"\"\n","    Filter out comments that have fewer words than numWords\n","\n","    :param df: dataframe\n","    :param numWords: int\n","    :return: dataframe with comments with fewer words than numWords filtered out\n","    \"\"\"\n","\n","    if \"comment_text_words\" not in df.columns:\n","        df = splitIntoWords(df)\n","\n","    return df.loc[df[\"comment_text_words\"].str.len() > numWords]\n","\n","\n","def filterNonEnglishChars(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","        Filter out non-english characters\n","\n","        :param df: dataframe\n","        :return: dataframe with non-english characters filtered out\n","    \"\"\"\n","\n","    # df[\"comment_text\"] = df['comment_text'].str \\\n","    #     .encode('ascii', 'ignore').str.decode('ascii')\n","    df[\"comment_text\"].replace(r\"[^A-Za-z\\s]+\", \"\", regex=True,\n","                               inplace=True)\n","\n","    return df\n","\n","\n","def removeStopWords(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Remove stop words\n","\n","    :param df: dataframe\n","    :return: dataframe with stop words removed\n","    \"\"\"\n","\n","    wordsToRemove = stopwords.words('english')\n","    pattern = r\"\\b({})\\b\".format('|'.join(wordsToRemove))\n","    df[\"comment_text\"] = df[\"comment_text\"].str.replace(\n","        pattern, \"\", regex=True)\n","\n","    return df\n","\n","\n","def toLowerCase(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Forces all characters to be lowercase\n","\n","    :param df: dataframe\n","    :return: dataframe with all characters forced to be lowercase\n","    \"\"\"\n","\n","    df[\"comment_text\"] = df[\"comment_text\"].str.lower()\n","\n","    return df\n","\n","\n","def splitIntoWords(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Split comments into words and forces them to be lowercase\n","\n","    :param df: dataframe\n","    :return: dataframe with comments split into words\n","    \"\"\"\n","\n","    df[\"comment_text_words\"] = df[\"comment_text\"].str.split(\"\\\\s+\")\n","\n","    return df\n","\n","\n","def isEnglish(s: str) -> bool:\n","    \"\"\"\n","    Check if a string contains all english characters\n","\n","    :param s: string to check\n","    :return: whether string contains only english characters\n","    \"\"\"\n","\n","    try:\n","        s.encode(encoding='utf-8').decode('ascii')\n","    except UnicodeDecodeError:\n","        return False\n","    else:\n","        return True\n","\n","\n","def trimWhitespace(df: pd.DataFrame) -> pd.DataFrame:\n","    df[\"comment_text\"] = df[\"comment_text\"].str.strip()\n","\n","    return df\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T07:19:35.911569Z","iopub.status.busy":"2023-03-04T07:19:35.910691Z","iopub.status.idle":"2023-03-04T07:19:59.803451Z","shell.execute_reply":"2023-03-04T07:19:59.801788Z","shell.execute_reply.started":"2023-03-04T07:19:35.911523Z"},"trusted":true},"outputs":[],"source":["def cleanData():\n","    df = pd.read_csv(\"/kaggle/input/toxic-message-classifier-dataset/train.csv\")\n","    df = toLowerCase(df)\n","    df = filterNonEnglishChars(df)\n","    df = removeStopWords(df)\n","    df = trimWhitespace(df)\n","    df = splitIntoWords(df)\n","    df = filterByNumWords(df, 3)\n","\n","    df.to_csv(\"train_cleaned.csv\", index=False)\n","\n","\n","cleanData()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
